{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rock-Paper-Scissor Against Deterministic Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../src\")\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import LearningGames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPS_vs_fixed:\n",
    "    action_set={\"R\",\"P\",\"S\"}\n",
    "    def __init__(self,fixed_action):\n",
    "        \"\"\"Create game\n",
    "\n",
    "        Args:\n",
    "            fixed_action: constant action for player 2\n",
    "        \"\"\"\n",
    "        self.fixed_action=fixed_action\n",
    "    def cost(self,p1_action,p2_action) -> float:\n",
    "        \"\"\"Returns game outcome\n",
    "\n",
    "        Args:\n",
    "            p1_action: action for player 1\n",
    "            p2_action: action for player 2\n",
    "\n",
    "        Returns:\n",
    "            game result (float): -1 if player 1 wins, +1 if player 1 loses, 0 draw\n",
    "        \"\"\"\n",
    "        if p1_action==p2_action:\n",
    "            # draw\n",
    "            return 0\n",
    "        if (p1_action==\"R\" and p2_action==\"S\") or (p1_action==\"P\" and p2_action==\"R\") or (p1_action==\"S\" and p2_action==\"P\"):\n",
    "            return -1\n",
    "        else:\n",
    "            return +1        \n",
    "    def play(self,p1_action) -> tuple[float,dict[str,float]]:      \n",
    "        \"\"\"Play game\n",
    "\n",
    "        Args:\n",
    "            p1_action: action for player 1\n",
    "\n",
    "        Returns: \n",
    "            tuple[float,dict(str,float)]\n",
    "            cost (float): -1 if player 1 wins, +1 if player 1 loses, 0 draw\n",
    "            all_costs (dict[str,float]): dictionary with costs for all actions of player 1\n",
    "        \"\"\"\n",
    "        # select action for player 2\n",
    "        p2_action=self.fixed_action\n",
    "        # cost for given action of player 1\n",
    "        cost=self.cost(p1_action,p2_action)\n",
    "        # costs for all actions of player 1\n",
    "        all_costs={a:self.cost(a,p2_action) for a in self.action_set}\n",
    "        return (cost,all_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LearningGame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Against a static player, we can use `gamma=0`\n",
    "+ Against a deterministic player, the temperature can be quite low. This will result in very fast learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/hespanha/GitHub/projects/LearningGames/examples/RPS_vs_fixed.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hespanha/GitHub/projects/LearningGames/examples/RPS_vs_fixed.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m game\u001b[39m=\u001b[39mRPS_vs_fixed(\u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hespanha/GitHub/projects/LearningGames/examples/RPS_vs_fixed.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lg\u001b[39m=\u001b[39mLearningGames\u001b[39m.\u001b[39;49mLearningGame(game\u001b[39m.\u001b[39;49maction_set,measurement_set\u001b[39m=\u001b[39;49mgame\u001b[39m.\u001b[39;49mmeasurement_set,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hespanha/GitHub/projects/LearningGames/examples/RPS_vs_fixed.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                               gamma\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,inverse_temperature\u001b[39m=\u001b[39;49m\u001b[39m.1\u001b[39;49m,seed\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m);\n",
      "File \u001b[0;32m~/GitHub/projects/LearningGames/examples/../src/LearningGames.py:66\u001b[0m, in \u001b[0;36mLearningGame.__init__\u001b[0;34m(self, action_set, measurement_set, gamma, inverse_temperature, seed)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_set \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39m(action_set)  \u001b[39m# to make it immutable\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"action_set (set[Action]): set of all possible actions\"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasurement_set \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39;49m(measurement_set)  \u001b[39m# to make it immutable\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"measurement_set (set[Measurement]): set of all possible measurements\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m=\u001b[39m gamma\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "game=RPS_vs_fixed(\"P\")\n",
    "lg=LearningGames.LearningGame(game.action_set,\n",
    "                              gamma=0.0,inverse_temperature=.1,seed=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.reset()\n",
    "M = 100\n",
    "costs=numpy.zeros(M)\n",
    "for iter in range(M):\n",
    "    # Play\n",
    "    action=lg.get_action(None)\n",
    "    (costs[iter],all_costs)=game.play(action)\n",
    "    # Learn\n",
    "    lg.update_energies(None, all_costs)\n",
    "    # output\n",
    "    if iter<10:\n",
    "        print(\"iter={:4d}, action = {:s}, cost = {:2.0f}, rewards = {:s}\".format(iter,action,costs[iter],str(all_costs)))\n",
    "    #print(lg.energy)\n",
    "lg.get_regret(display=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(range(M),costs,'.',label='cost')\n",
    "plt.plot(range(M),numpy.divide(numpy.cumsum(costs),numpy.add(range(M),1)),'-',label='average cost')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('cost');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
